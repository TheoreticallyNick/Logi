DEVELOPMENT ENTRIES

Date: 9/7/19
Task: Connecting the Beaglebone on the AWS IoT - Completed
Notes: 
    - Had recurring timeout issues when trying to connect to AWS. It was found that 
    any timeout issue was directly related to the policy document attached to
    the thing's certficate. Another issue that resulted in timeout issues is that
    the BBB was not connected to the internet
    
    - Had recurring timeout issues related to publishing messages to the AWS shadow.
    This is different from the connection issues above. The policy document had to 
    be updated so that the policy gives publish, receive, and subscribe access to
    all topics related to the shadow.
    
    - Issues with setting up a device. When adding a new thing, use "AWS Configure a
    New Device Wizard". Trying to set up a device often runs into connection issues,
    although it may have been a policy document issue that was resolved later.
    
Date: 9/8/19
Task: Gathering Beaglebone Data into IoT Analytics - Incomplete
Notes:
    - Recurring issues when creating the channel - the topic subscription of the
    channel does not become available unless you create an S3 bucket specifically
    for the channel. S3 buckets must be created for each of the processes in IoT
    analytics and subsequently bridged to the channel/datastore/dataset.
    
    - Had a single success in sending messages through the channel, however, these 
    messages were capped at 15 messages. Don't know if this a cap placed by Amazon
    or if connection was lost. I also believe that it may be an issue with the
    policy documents for the S3 buckets
    
    - I need to better understand what an S3 bucket is and how it works in relation
    to the channel/datastore/dataset from IoT Analytics.
    
    - The shadow topic that publishes the accepted MQTT messages coming from the 
    Bone are published in "$aws/things/BBBK052F/shadow/update/accepted"
    
Date: 9/10/19
Task: Gathering Beaglebone Data into IoT Analytics - Incomplete
Notes: 
    - Attempted to create a new channel along with really digging into the IAM and
    creating a role and policy that has all the appropriate permissions for data
    to flow between the IoT and IoT Analytics, unfortunately no success. Even when
    using the "test" function in the IoT dashboard, the channel does not receive
    the messages.
    
Date: 9/15/19
Task: Gathering Beaglebone Data into IoT Analytics - Completed
Notes:
    - Attempted once again to pipe data from IoT Core to IoT Analytics. I was
    successful after changing the channel name that IoT was sending the data 
    to in the "Act" panel of IoT Core. Once the name of the channel was changed
    to the correct channel, data was flowing to the channel correctly and being
    properly in the channel's S3 bucket.
    - Once the data was flowing to the channel, creating the pipeline and the
    datastore was an easy process. I can confirm that json data is making it to
    the datastore effectively.

Date: 9/15/19  
Task: Querying Data from Datastore to Data Analytics - Incomplete
Notes:
    - After successfully creating the channel, pipeline, and the datastore, and 
    flowing data from the Beaglebone to it, I met resistance when trying to send 
    the data from the datastore to the dataset. Unfortunately, when querying the
    data from the datastore, I am only able to retrieve the "__dt" data, and not
    the temperature and pressure data that I am looking for.
    
Date: 9/17/19
Task: Sending MQTT Message to the Beaglebone - Completed
Notes:
    - After looking at documentation online (see below), i was able to connect 
    the BBB to a "non-shadow" client of AWS IoT to send and receive messages via
    MQTT. The trick here was to really open up the policy to allow publish and 
    subscribe for any topic.
    - Unfortunately, as much as I want to keep it nice and direct in the Policy 
    document, it is better to open up the pub/sub restrictions for any topic. This
    was the only way to enable the connection to the non-shadow client for the BBB
    to communicate with topics in AWS core.
    
Date: 9/18/19  
Task: Querying Data from Datastore to Data Analytics - Completed
Notes:
    - After successfully connecting to the MQTTClient, the non-shadow client, I
    created a new channel, pipeline, etc... with the AWS auto generator. It became
    apparent that this method would be much more effective at creating the dataflows.
    I can confirm that the correct data was piped properly to the dataset and
    viewable. Great success.
    
Date: 9/21/19  
Task: Visualizing the Data in Quicksights - Incomplete
Notes: 
    - First thing to note is that the format of the JSON file being published to 
    the topic does not have to reflect the JSON of the shadow file. Changing this 
    was a huge improvement in the pipeline and datastore for the info coming from
    the device.
    - Unfortunately, once the data was being formatted and sent correctly to the
    dataset of the IoT Analytics dataset, Quicksight proved to be quite hard to 
    use for the current application, moving forward I will not use Quicksights and
    will use either the Jupyter Notebooks or a different way to publish the data
    to the internet (R-studio?).

Next Steps: Connect the RaspPi to the same IoT Core and pipe similar data to IoT
    Analytics and see what the implications are of sending data from two devices.
    
Date: 9/22/19
Task: Connect the Sensor and Pipe Data to AWS IoT - Completed
Notes:
    - The sensor's leads were soldered and connected to the Beaglebone.
    - Significant troubleshooting was done to understand the I2C interface, check 
    out the MPL3115A2 python file to look at the addresses and commands for the
    interface. Kept getting a "Device is being used" error -- it turns out that 
    the bus interface function (bus = smbus.SMBus(2)) needed to be set to I2C port
    #2 to work properly. Once the port was set, there were no further issues 
    collecting data from the sensor.
    - Once the sensor was hooked up and sensor data could be gathered, there were 
    no issues in coverting the data to a JSON document and piping it to AWS IoT.

Date: 10/26/19
Task: Flash the Beaglebone to latest Debian IoT Image - Completed
Notes:
    - To flash board to factory image:
    1) Download the image
    2) write the image to a microSD card using diskformatter
    3) Insert into beaglebone
    4) Hold down S2 button and power up beaglebone via USB
    5) SSH into the board, and enter the following command:
        -> sudo nano /boot/uEnv.txt
    6) find and uncomment the following line
        -> cmdline=init=/opt/scripts/tools/eMMC/init-eMMC-flasher-v3.sh
    7) save and exit
    8) unplug beaglebone from laptop, hold down the S2 button, and power the beaglebone through the 5V barrel jack
    9) hold S2 button until the lights come on and then turn off
    10) wait for 30s, you will know it is being reflashed correctly once the 4 LED's start pulsating back and forth
    11) Once the lights turn off, remove power, and remove the microSD car from device


Date: 10/27/19
Task: Connect Wifi Beaglebone to Wifi Router and set static IP - Completed
Notes:
    - Using Connman, enter the following into the terminal:
    1) debian@beaglebone:~$ connmanctl
        output: Error getting VPN connections: The name net.connman.vpn was not provided by any
    2) connmanctl > enable wifi
        output: Error wifi: Already enabled
    3) connmanctl > scan wifi
        output: Scan completed for wifi
    4) connmanctl > services
        output: (list of all wifi signals available)
    5) connmanctl > agent on
        output: Agent registered
    6) connmanctl > connect wifi_*******_managed_psk
        output: Passphrase?
    7) connmanctl > <enter password>
        output: Connected
    8) connmanctl > config wifi_*******_managed_psk --ipv4 manual <IP Address> <Sub Net Mask> <IP Gateway> --nameservers <8.8.8.8>

Date: 10/27/19
Task: Connect Beaglebone to RemoteIoT's VPN - Completed
Notes:
    - Steps of what had to be installed on bone:
    1) sudo apt-get update
    2) sudo apt-get install software-properties-common
    3) sudo apt-get install dirmngr --install-recommends
    4) sudo apt-get -y install openjdk-8-jre-headless
    5) curl -s -L https://remoteiot.com/install/remote-iot-install.sh | sudo -s bash
    6) sudo /etc/remote-iot/services/setup.sh 'your_login_email' 'your_password' 'device_name'
    - This ultmimately was the first solution that worked properly and allowed me to SSH into the devices remotely.

Date: 10/27/19
Task: Update Logi Software and Enable Boot Start - Incomplete
Notes:
    - Restructured the files of Logi project. focusing on using OOP to structure and breakdown code into different
    pieces
    - Unsuccessfully attempted to set boot start of the software.

Date: 10/30/19
Task: Correlate Thermocouple Voltage Readouts to Temperature - Failure
Notes:
    - DO NOT PUT A BEAGLEBONE IN THE FREEZER, I FRIED THE BEAGLEBONE DOING THIS
    - Best way to test this is to have the beaglebone outside the freezer.
    - I had a script that was working, but unfortunately, lost all of it when the beaglebone fried because
    I didn't save any of it.

Date: 11/7/19
Task: Setup the Bones for Prototype phase
Notes: 
    - Setup the bones successfully across AWS IoT, and Remote IoT
    - All bones have software version 1.0.0
    - ready to deploy bone 15, 21, 23
    - Next move is to inspect and integrate the gauge hall sensor with our device

Date: 11/9/19
Task: Install Logi 1.0 on Dad's Grill Propane Tanks
Notes: 
    - Had a few connection issues between the wires, but otherwise fixed
    - PX3 Sensor calibration was a success -- turns out it is a perfectly linear 
        relationship between sensor voltage and gauge pressure
    - As expected, the pressure inside the tank remains the same over time, 
        as propane evaporates inside the tank until the pressure reaches equilibrium point 
Next Steps:
    - Run the program outside of the Cloud9 directory
    - Have the red light turn on as soon as it is powered up
    - Start moving towards the Hall Sensor from Ebay and get it programed to do the same thing.
    - Set up appropriate channels, pipes, and databases on AWS
    - identify a Cat M1 chip to use with Beaglebone and pull the trigger

Date: 11/15/19
Task: Install Python 3.7 on the Beaglebone
Notes: 
    - use the following commands to install python 3.7 on the beaglebone
    1) Flash the Beaglebone Black with the latest Debian image from here (version 9.9 as I’m writing this): https://beagleboard.org/latest-images 1
        ssh into your beaglebone and login
    2) enter command: sudo apt-get update
    3) remove all of python3.5 using command: sudo apt-get remove python3 – 
        the BBB’s Debian image comes with both python 2.7 and python 3.5, both of which will not work with Hologram’s SDK. 
        You must delete python3.5 prior to installing python3.7 to avoid pip install from installing packages in the wrong python directory.
    4) install python 3.7 using the instructions here: https://linuxize.com/post/how-to-install-python-3-7-on-debian-9/ 3
    5) as a precaution, I also removed every file and directory related to python3.5 in the /usr/bin/ and /usr/local/lib directories
    6) enter command: python3 -m pip install hologram-python
    7) enter command: hologram activate
    8) sign into hologram and choose the plan

Date: 12/8/19
Task: Structuring and Organizing Devices and Data
Notes:
    - Created a version control of the mqtt schema
    - Seperated the wifi vs cellular scripts

Date: 1/12/20
Task: Connect all components and test the board with a 20Ah battery
Notes:
    - Must find a compact and robust way to connect all junctions in Logi


Date: 2/4/20
Task: Resolve OSError 24
Notes:
    - Used a different subprocess.Popen, with an ending closing statement

Date: 2/16/20
Task: Resolve OSError 24
Notes:
    - The previous fix didn't work. At this point, I do not believe that it is a problem related with the code
    - Strong belief that it is due to too many devices accessing the same Policy statemtn at the same time.
    - Each device now has its own policy statement -- observing for changes.
